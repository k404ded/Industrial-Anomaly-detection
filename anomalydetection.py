# -*- coding: utf-8 -*-
"""AnomalyDetection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12fPcmNB0UouVWM1A1CUOSOgLwA-UV-92

**DUMMY MODEL**

**Import Libraries**
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.ensemble import IsolationForest
from sklearn.preprocessing import StandardScaler

"""**Creating Sample data (Normal+Anomalies)**"""

np.random.seed(42)

# Normal machine data
normal_data = pd.DataFrame({
    "temperature": np.random.normal(60, 5, 300),
    "vibration": np.random.normal(30, 3, 300),
    "pressure": np.random.normal(100, 10, 300),
    "rpm": np.random.normal(1500, 100, 300),
    "current": np.random.normal(10, 1, 300)
})

# Anomalous machine data
anomaly_data = pd.DataFrame({
    "temperature": np.random.normal(90, 5, 20),
    "vibration": np.random.normal(60, 5, 20),
    "pressure": np.random.normal(150, 10, 20),
    "rpm": np.random.normal(2500, 200, 20),
    "current": np.random.normal(20, 2, 20)
})

"""**Combining Both**"""

data = pd.concat([normal_data, anomaly_data], ignore_index=True)

print("Dataset shape:", data.shape)
print(data.head())

"""**Normalise Data**"""

scaler = StandardScaler()
scaled_data = scaler.fit_transform(data)

"""**Training Data**"""

model = IsolationForest(
    n_estimators=100,
    contamination=0.06,   # expected anomaly %
    random_state=42
)

model.fit(scaled_data)

"""**Predicting Anomalies**"""

data["anomaly"] = model.predict(scaled_data)

# Convert labels
# -1 = anomaly, 1 = normal
data["anomaly"] = data["anomaly"].map({1: 0, -1: 1})

print("\nAnomaly count:")
print(data["anomaly"].value_counts())

"""**Visualising the data**"""

plt.figure()
plt.scatter(data.index, data["temperature"], c=data["anomaly"])
plt.title("Industrial Anomaly Detection (Temperature)")
plt.xlabel("Sample")
plt.ylabel("Temperature")
plt.show()

"""**Show detected anomalies**"""

anomalies = data[data["anomaly"] == 1]
print("\nDetected anomalies:")
print(anomalies)

"""**Comparison Table**"""

# Step 8: Create comparison table

comparison_table = data.copy()

# Add readable label
comparison_table["prediction_label"] = comparison_table["anomaly"].map({
    0: "Normal",
    1: "Anomaly"
})

print("\nComparison Table:")
print(comparison_table)

"""**Training on Real time model**"""

df = pd.read_csv("/content/ai4i2020.csv")

df.head()

df.columns

df.describe()

df.shape

"""**Selecting only SENSOR FEATURES for ML**"""

features = df[
    [
        "Air temperature [K]",
        "Process temperature [K]",
        "Rotational speed [rpm]",
        "Torque [Nm]",
        "Tool wear [min]"
    ]
]

"""**Actual Lables**"""

actual = df["Machine failure"]

"""**Normalize Data**"""

scaler = StandardScaler()
scaled_features = scaler.fit_transform(features)

"""**Training Isolation Forest**"""

model = IsolationForest(
    n_estimators=100,
    contamination=0.03,
    random_state=42
)

model.fit(scaled_features)

"""**Predicting Anomalies**"""

predictions = model.predict(scaled_features)

# convert format
predictions = np.where(predictions == -1, 1, 0)

df["Predicted Anomaly"] = predictions
df["Actual Failure"] = actual

"""**Comparision Table**"""

comparison = df[
    [
        "Air temperature [K]",
        "Process temperature [K]",
        "Rotational speed [rpm]",
        "Torque [Nm]",
        "Tool wear [min]",
        "Actual Failure",
        "Predicted Anomaly"
    ]
]

print(comparison.head)

"""**Counting Comparision**"""

print("\nActual failures:")
print(df["Actual Failure"].value_counts())

print("\nPredicted anomalies:")
print(df["Predicted Anomaly"].value_counts())

"""**Accuracy Check**"""

from sklearn.metrics import confusion_matrix, classification_report

print(confusion_matrix(actual, predictions))
print(classification_report(actual, predictions))

"""**Normal v/s Anomaly**"""

plt.figure()

plt.scatter(
    df["Rotational speed [rpm]"],
    df["Torque [Nm]"],
    c=df["Predicted Anomaly"]
)

plt.xlabel("Rotational speed (rpm)")
plt.ylabel("Torque (Nm)")
plt.title("Anomaly Detection Visualization")

plt.show()

"""**Actual Failure v/s Predicted Anomaly**"""

cm = confusion_matrix(df["Actual Failure"], df["Predicted Anomaly"])

plt.figure()
plt.imshow(cm)

plt.title("Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")

plt.colorbar()

plt.show()

print(cm)

"""**Tool Wear v/s Failure**"""

plt.figure()

df.boxplot(column="Tool wear [min]", by="Predicted Anomaly")

plt.title("Tool Wear Distribution for Normal vs Anomalous Machines")
plt.suptitle("")
plt.xlabel("0 = Normal, 1 = Anomaly")
plt.ylabel("Tool wear (min)")

plt.show()

"""**Temperature over time**"""

plt.figure()

plt.plot(df["Process temperature [K]"])

plt.title("Process Temperature Trend Over Time")
plt.xlabel("Sample number")
plt.ylabel("Temperature (K)")

plt.show()

"""**Normal v/s Anomaly**"""

counts = df["Predicted Anomaly"].value_counts()

plt.figure()

counts.plot(kind="bar")

plt.title("Number of Normal vs Anomalous Machine States")
plt.xlabel("0 = Normal, 1 = Anomaly")
plt.ylabel("Count")

plt.show()

"""**Sensor comparision**"""

import seaborn as sns
import matplotlib.pyplot as plt

# set professional style
sns.set(style="whitegrid")

# list of sensor columns
sensor_columns = [
    "Air temperature [K]",
    "Process temperature [K]",
    "Rotational speed [rpm]",
    "Torque [Nm]",
    "Tool wear [min]"
]

# create subplot grid
fig, axes = plt.subplots(2, 3, figsize=(15, 10))

axes = axes.flatten()

# create boxplot for each sensor
for i, col in enumerate(sensor_columns):

    sns.boxplot(
        x="Predicted Anomaly",
        y=col,
        data=df,
        ax=axes[i]
    )

    axes[i].set_title(f"{col} vs Anomaly")
    axes[i].set_xlabel("0 = Normal, 1 = Anomaly")
    axes[i].set_ylabel(col)

# remove empty last plot
fig.delaxes(axes[5])

plt.suptitle("Industrial Machine Sensor Dashboard", fontsize=16)

plt.tight_layout()

plt.show()

